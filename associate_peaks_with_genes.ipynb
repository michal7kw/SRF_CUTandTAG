{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pybedtools\n",
    "from pybedtools import BedTool\n",
    "import sys\n",
    "import os\n",
    "\n",
    "wd_dir = '/beegfs/scratch/ric.broccoli/kubacki.michal/SRF_CUTandTAG'\n",
    "os.chdir(wd_dir)\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bed_from_peaks(peaks_df):\n",
    "    \"\"\"\n",
    "    Convert peak coordinates to BED format\n",
    "    \"\"\"\n",
    "    # Split the chromosome coordinates\n",
    "    peaks_df[['chrom', 'coords']] = peaks_df['gene'].str.split(':', n=1, expand=True)\n",
    "    peaks_df[['start', 'end']] = peaks_df['coords'].str.split('-', expand=True)\n",
    "    \n",
    "    # Convert start and end to integers\n",
    "    peaks_df['start'] = peaks_df['start'].astype(int)\n",
    "    peaks_df['end'] = peaks_df['end'].astype(int)\n",
    "    \n",
    "    # Create BED format DataFrame\n",
    "    bed_df = peaks_df[['chrom', 'start', 'end']].copy()\n",
    "    return bed_df\n",
    "\n",
    "def parse_gtf_attributes(attribute_str):\n",
    "    \"\"\"\n",
    "    Parse GTF attribute string to get gene_name\n",
    "    \"\"\"\n",
    "    attrs = {}\n",
    "    for attr in attribute_str.split('; '):\n",
    "        if attr:\n",
    "            try:\n",
    "                key, value = attr.split(' ', 1)\n",
    "                attrs[key] = value.strip('\"')\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return attrs\n",
    "\n",
    "def create_gene_bed_from_gtf(gtf_file):\n",
    "    \"\"\"\n",
    "    Create BED file from GTF containing only genes\n",
    "    \"\"\"\n",
    "    genes = []\n",
    "    with open(gtf_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) < 9 or fields[2] != 'gene':\n",
    "                continue\n",
    "            \n",
    "            chrom = fields[0]\n",
    "            start = int(fields[3]) - 1  # Convert to 0-based\n",
    "            end = int(fields[4])\n",
    "            attributes = parse_gtf_attributes(fields[8])\n",
    "            gene_name = attributes.get('gene_name', 'Unknown')\n",
    "            \n",
    "            genes.append([chrom, start, end, gene_name])\n",
    "    \n",
    "    gene_df = pd.DataFrame(genes, columns=['chrom', 'start', 'end', 'gene_name'])\n",
    "    return BedTool.from_dataframe(gene_df)\n",
    "\n",
    "def get_gene_symbols(peaks_df, gtf_file):\n",
    "    \"\"\"\n",
    "    Add gene symbols to peaks DataFrame using GENCODE GTF\n",
    "    \"\"\"\n",
    "    # Create BED file from peaks\n",
    "    bed_df = create_bed_from_peaks(peaks_df)\n",
    "    peaks_bed = BedTool.from_dataframe(bed_df)\n",
    "    \n",
    "    # Create BED from GTF genes\n",
    "    genes_bed = create_gene_bed_from_gtf(gtf_file)\n",
    "    \n",
    "    # Intersect peaks with genes\n",
    "    intersect = peaks_bed.intersect(genes_bed, wa=True, wb=True)\n",
    "    \n",
    "    # Create dictionary to store peak to gene symbol mappings\n",
    "    peak_to_gene = {}\n",
    "    for intersection in intersect:\n",
    "        peak_key = f\"{intersection[0]}:{intersection[1]}-{intersection[2]}\"\n",
    "        gene_symbol = intersection[6]  # gene_name field from our gene BED\n",
    "        if peak_key in peak_to_gene:\n",
    "            if gene_symbol not in peak_to_gene[peak_key].split(';'):\n",
    "                peak_to_gene[peak_key] += f\";{gene_symbol}\"\n",
    "        else:\n",
    "            peak_to_gene[peak_key] = gene_symbol\n",
    "    \n",
    "    # Add gene symbols to original DataFrame\n",
    "    peaks_df['gene_symbol'] = peaks_df['gene'].map(peak_to_gene)\n",
    "    \n",
    "    # Fill NA with \"Intergenic\"\n",
    "    peaks_df['gene_symbol'] = peaks_df['gene_symbol'].fillna('Intergenic')\n",
    "    \n",
    "    return peaks_df\n",
    "\n",
    "def process_files(input_file, output_file, gtf_file):\n",
    "    \"\"\"\n",
    "    Process input CSV file and write annotated results to output file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read input data\n",
    "        peaks_df = pd.read_csv(input_file)\n",
    "        \n",
    "        # Add gene symbols\n",
    "        result_df = get_gene_symbols(peaks_df, gtf_file)\n",
    "        \n",
    "        # Save results\n",
    "        result_df.to_csv(output_file, index=False)\n",
    "        print(f\"Successfully processed {input_file} and saved results to {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing files: {str(e)}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed custom_pipeline/results/Neuron_peak_analysis.csv and saved results to custom_pipeline/results/Neuron_peak_analysis_annotated.csv\n",
      "Successfully processed custom_pipeline/results/NSC_peak_analysis.csv and saved results to custom_pipeline/results/NSC_peak_analysis_annotated.csv\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "input_files = ['custom_pipeline/results/Neuron_peak_analysis.csv', 'custom_pipeline/results/NSC_peak_analysis.csv']\n",
    "gtf_file = 'custom_pipeline/DATA/gencode.vM10.annotation.gtf'\n",
    "\n",
    "# Process each input file\n",
    "for input_file in input_files:\n",
    "    output_file = input_file.replace('.csv', '_annotated.csv')\n",
    "    process_files(input_file, output_file, gtf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
