# Snakefile for cut&tag analysis

import os
from os.path import join
from snakemake.utils import min_version
import re

# Set minimum snakemake version
min_version("6.0")

# Set pipeline directory path
PIPELINE_DIR = os.environ.get("PIPELINE_DIR", "/beegfs/scratch/ric.broccoli/kubacki.michal/SRF_CUTandTAG/snake_pipeline")
DATA_DIR = os.environ.get("DATA_DIR", "/beegfs/scratch/ric.broccoli/kubacki.michal/SRF_CUTandTAG/DATA")

# Load configuration from config.yaml file
configfile: os.path.join(PIPELINE_DIR, "configs/config.yaml")

# raw fastq files for each experiment
EXOGENOUS = os.path.join(DATA_DIR, "EXOGENOUS")
ENDOGENOUS = os.path.join(DATA_DIR, "ENDOGENOUS")

# main output directory where all results will be stored
OUTPUT = os.path.join(PIPELINE_DIR, "results")

# Get sample names from input directories
EXOGENOUS_SAMPLES = [f.split("_R1")[0] for f in os.listdir(EXOGENOUS) if f.endswith("R1_001.fastq.gz")]
ENDOGENOUS_SAMPLES = [f.split("_R1")[0] for f in os.listdir(ENDOGENOUS) if f.endswith("R1_001.fastq.gz")]

# Make sure IgM is in ENDOGENOUS_SAMPLES if it's not already there
if "IgM" not in ENDOGENOUS_SAMPLES and "IgM_R1_001.fastq.gz" in os.listdir(ENDOGENOUS):
    ENDOGENOUS_SAMPLES.append("IgM")

# Define ALL_SAMPLES
ALL_SAMPLES = list(set(EXOGENOUS_SAMPLES + ENDOGENOUS_SAMPLES))
print(f"Running in full mode with {len(ALL_SAMPLES)} samples")

# Global variable to control skipping of non-peak steps
ONLY_PEAKS = 0

# Function to get input directory for a sample
def get_input_dir(sample):
    # For IgM (control), always use ENDOGENOUS directory
    if sample == "IgM":
        return ENDOGENOUS
    # For other samples, check their respective directories
    elif sample in EXOGENOUS_SAMPLES:
        return EXOGENOUS
    elif sample in ENDOGENOUS_SAMPLES:
        return ENDOGENOUS
    else:
        raise ValueError(f"Unknown sample: {sample}")

# Function to get experiment type for a sample
def get_experiment(sample):
    if sample in EXOGENOUS_SAMPLES:
        return "EXOGENOUS"
    elif sample in ENDOGENOUS_SAMPLES:
        return "ENDOGENOUS"
    elif sample == "IgM":  # Control sample can be used for both
        return "CONTROL"
    else:
        raise ValueError(f"Unknown sample: {sample}")

# specifies all output files to be generated
rule all:
    input:
        # Basic processing (always included)
        expand(join(OUTPUT, "fastqc", "{sample}_R1_001_fastqc.html"), sample=ALL_SAMPLES),
        expand(join(OUTPUT, "fastqc", "{sample}_R2_001_fastqc.html"), sample=ALL_SAMPLES),
        expand(join(OUTPUT, "trimmed", "{sample}_R1_001_val_1.fq.gz"), sample=ALL_SAMPLES),
        expand(join(OUTPUT, "trimmed", "{sample}_R2_001_val_2.fq.gz"), sample=ALL_SAMPLES),
        expand(join(OUTPUT, "aligned", "{sample}.bam"), sample=ALL_SAMPLES),
        expand(join(OUTPUT, "aligned", "{sample}.bam.bai"), sample=ALL_SAMPLES),
        expand(join(OUTPUT, "peaks", "{sample}_peaks.narrowPeak"), sample=ALL_SAMPLES),
        # MultiQC report
        join(OUTPUT, "multiqc", "multiqc_report.html")

# Rule to run FastQC on raw reads
rule fastqc:
    input:
        r1 = lambda wildcards: os.path.join(get_input_dir(wildcards.sample), 
                                          f"{wildcards.sample}_R1_001.fastq.gz"),
        r2 = lambda wildcards: os.path.join(get_input_dir(wildcards.sample), 
                                          f"{wildcards.sample}_R2_001.fastq.gz")
    output:
        html_r1 = join(OUTPUT, "fastqc", "{sample}_R1_001_fastqc.html"),
        html_r2 = join(OUTPUT, "fastqc", "{sample}_R2_001_fastqc.html"),
        zip_r1 = join(OUTPUT, "fastqc", "{sample}_R1_001_fastqc.zip"),
        zip_r2 = join(OUTPUT, "fastqc", "{sample}_R2_001_fastqc.zip")
    log:
        join(OUTPUT, "logs", "fastqc", "{sample}.log")
    threads: 2
    resources:
        mem_mb=24000,
        time="2:00:00",
        skip=ONLY_PEAKS
    shell:
        """
        if [ "{resources.skip}" = "1" ]; then
            touch {output.html_r1} {output.html_r2} {output.zip_r1} {output.zip_r2}
        else
            fastqc {input.r1} {input.r2} -o $(dirname {output.html_r1}) -t {threads} 2> {log}
        fi
        """

# Rule to trim reads using Trim Galore
rule trim_reads:
    input:
        r1 = lambda wildcards: os.path.join(get_input_dir(wildcards.sample), 
                                          f"{wildcards.sample}_R1_001.fastq.gz"),
        r2 = lambda wildcards: os.path.join(get_input_dir(wildcards.sample), 
                                          f"{wildcards.sample}_R2_001.fastq.gz")
    output:
        r1 = join(OUTPUT, "trimmed", "{sample}_R1_001_val_1.fq.gz"),
        r2 = join(OUTPUT, "trimmed", "{sample}_R2_001_val_2.fq.gz")
    log:
        join(OUTPUT, "logs", "trim_galore", "{sample}.log")
    threads: 16
    resources:
        mem_mb=32000,
        time="6:00:00",
        skip=ONLY_PEAKS
    params:
        output_dir = join(OUTPUT, "trimmed")
    shell:
        """
        if [ "{resources.skip}" = "1" ]; then
            touch {output.r1} {output.r2}
        else
            # Create output directory
            mkdir -p {params.output_dir}
            
            # Run trim_galore
            trim_galore --paired \
                --gzip \
                --fastqc \
                --cores {threads} \
                --output_dir {params.output_dir} \
                {input.r1} {input.r2} \
                2> {log}

            # Rename output files to match expected names
            mv {params.output_dir}/{wildcards.sample}_R1_001_trimmed.fq.gz {output.r1}
            mv {params.output_dir}/{wildcards.sample}_R2_001_trimmed.fq.gz {output.r2}

            # Verify the output files exist and are not empty
            if [ ! -s {output.r1} ] || [ ! -s {output.r2} ]; then
                echo "Error: Trimmed output files are empty or missing" >> {log}
                exit 1
            fi
        fi
        """

# Rule to align trimmed reads
rule align:
    input:
        r1 = rules.trim_reads.output.r1,
        r2 = rules.trim_reads.output.r2
    output:
        bam = temp(join(OUTPUT, "aligned", "{sample}.unsorted.bam")),
        sorted_bam = join(OUTPUT, "aligned", "{sample}.bam"),
        bai = join(OUTPUT, "aligned", "{sample}.bam.bai")
    log:
        join(OUTPUT, "logs", "bowtie2", "{sample}.log")
    threads: 32
    resources:
        mem_mb=96000,
        time="8:00:00",
        skip=ONLY_PEAKS
    params:
        max_fragment = config["bowtie2_params"]["max_fragment_length"],
        sort_memory = "2G",
        tmp_dir = os.path.join(PIPELINE_DIR, "tmp")
    shell:
        """
        if [ "{resources.skip}" = "1" ]; then
            touch {output.bam}
            touch {output.sorted_bam}
            touch {output.bai}
        else
            # Create temporary directory for this job
            TEMP_DIR=$(mktemp -d -p {params.tmp_dir})
            
            # Align reads with optimized parameters
            bowtie2 \
                -p {threads} \
                -x {config[genome_index]} \
                -1 {input.r1} -2 {input.r2} \
                --local --very-sensitive-local \
                --no-mixed --no-discordant \
                --maxins {params.max_fragment} \
                --mm \
                2> {log} | \
            samtools view -@ {threads} -bS -q 30 - > {output.bam}

            # Sort BAM file using multiple threads and temporary directory
            samtools sort \
                -@ {threads} \
                -m {params.sort_memory} \
                -T $TEMP_DIR/{wildcards.sample} \
                -o {output.sorted_bam} \
                {output.bam}

            # Index BAM file
            samtools index -@ {threads} {output.sorted_bam}
            
            # Cleanup
            rm -rf $TEMP_DIR
        fi
        """

# Rule to call peaks using MACS2
rule call_peaks:
    input:
        treatment = join(OUTPUT, "aligned", "{sample}.bam"),
        treatment_index = join(OUTPUT, "aligned", "{sample}.bam.bai"),
        control = lambda wildcards: [] if wildcards.sample == "IgM" else join(OUTPUT, "aligned", "IgM.bam"),
        control_index = lambda wildcards: [] if wildcards.sample == "IgM" else join(OUTPUT, "aligned", "IgM.bam.bai")
    output:
        peaks = join(OUTPUT, "peaks", "{sample}_peaks.narrowPeak")
    log:
        join(OUTPUT, "logs", "macs2", "{sample}.log")
    threads: 16
    resources:
        mem_mb=32000,
        time="4:00:00"
    params:
        genome_size = config['effective_genome_size'],
        format = "BAMPE",
        qvalue = "0.05",
        outdir = lambda wildcards, output: os.path.dirname(output.peaks),
        control_param = lambda wildcards, input: "" if wildcards.sample == "IgM" else f"-c {input.control}"
    shell:
        """
        mkdir -p {params.outdir}
        macs2 callpeak \
            -t {input.treatment} \
            {params.control_param} \
            -f {params.format} \
            -g {params.genome_size} \
            -n {wildcards.sample} \
            --outdir {params.outdir} \
            -q {params.qvalue} \
            --nomodel \
            --keep-dup all \
            --call-summits \
            2> {log}
        """

# Rule to run MultiQC to aggregate QC reports
rule multiqc:
    # takes all fastqc and aligned bam files from previous rules
    input:
        expand(join(OUTPUT, "fastqc", "{sample}_R1_001_fastqc.html"), sample=ALL_SAMPLES),
        expand(join(OUTPUT, "fastqc", "{sample}_R2_001_fastqc.html"), sample=ALL_SAMPLES),
        expand(join(OUTPUT, "aligned", "{sample}.bam"), sample=ALL_SAMPLES)
    # outputs multiqc report
    output:
        report = join(OUTPUT, "multiqc", "multiqc_report.html")
    log:
        join(OUTPUT, "logs", "multiqc", "multiqc.log")
    resources:
        mem_mb=16000,
        time="1:00:00"
    shell:
        "multiqc {OUTPUT} -o {OUTPUT}/multiqc &> {log}"

wildcard_constraints:
    sample="|".join([re.escape(x) for x in (EXOGENOUS_SAMPLES + ENDOGENOUS_SAMPLES + ["IgM"])]),
